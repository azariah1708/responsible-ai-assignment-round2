# 🕵️ Responsible AI Inspector – Assignment (Round 2)

Welcome back to another mission into the world of AI ethics. As Responsible AI Inspectors, we’re here to uncover where machines mess up — and how to fix them with fairness, logic, and a little bit of soul. Let’s dive in. 💻⚖️

---

## 📍 Case 1: The Biased Hiring Bot

### 👀 What’s Happening  
A company uses AI to filter job applicants before they reach a human. The system ends up rejecting many female candidates, especially those with gaps in their careers.

### 🚨 What’s Problematic  
The AI has learned patterns from biased past data — likely reflecting outdated hiring practices. Instead of improving fairness, it reinforces discrimination, especially against women who took time off for caregiving or personal reasons.

### 💡 One Improvement Idea  
Retrain the model using inclusive data that reflects a variety of career paths. Add regular fairness audits to monitor performance across gender, age, and career gap status. Let humans make the final hiring call — not just bots.

---

## 📍 Case 2: The AI That Accuses Students

### 👀 What’s Happening  
During remote exams, schools use an AI proctoring tool to detect cheating. It flags students based on eye movement or looking away from the screen — often misidentifying neurodivergent students.

### 🚨 What’s Problematic  
The system lacks awareness of neurodiversity and treats all students the same. It flags behavior that is totally normal for students with ADHD, autism, or anxiety — leading to unfair accusations and stress. There’s also the issue of surveillance and privacy.

### 💡 One Improvement Idea  
Design with neurodiversity in mind. Allow flexible behavior profiles and let students customize their exam experience. AI should assist human proctors — not replace them — to ensure real understanding of context.

---

## 🧭 Final Thoughts  
AI isn’t just code — it’s power. And with that power comes responsibility. Whether hiring or learning, our systems must be built on fairness, inclusion, and empathy. If we want better outcomes, we need better inputs — and better values.

> Build smart. Build fair. Build for everyone. 🚀

---

📁 Repo by [azariah1708](https://github.com/azariah1708)
